{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import library yang digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from num2words import num2words\n",
    "import re\n",
    "import string\n",
    "import emoji\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>emoji</th>\n",
       "      <th>cleantext</th>\n",
       "      <th>terbilang</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>delangka</th>\n",
       "      <th>normalisasi</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>polarity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turunkan tunjangan untuk DPR, alihkan untuk su...</td>\n",
       "      <td>abu studio chanel</td>\n",
       "      <td>Turunkan tunjangan untuk DPR, alihkan untuk su...</td>\n",
       "      <td>turunkan tunjangan untuk dpr alihkan untuk sub...</td>\n",
       "      <td>turunkan tunjangan untuk dpr alihkan untuk sub...</td>\n",
       "      <td>[turunkan, tunjangan, untuk, dpr, alihkan, unt...</td>\n",
       "      <td>turunkan tunjangan untuk dpr alihkan untuk sub...</td>\n",
       "      <td>[turunkan, tunjangan, untuk, dpr, alihkan, unt...</td>\n",
       "      <td>[turun, tunjang, untuk, dpr, alih, untuk, subs...</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Terimakasih pak de Saya seorang tukang ojek ka...</td>\n",
       "      <td>al rozaq</td>\n",
       "      <td>Terimakasih pak de Saya seorang tukang ojek ka...</td>\n",
       "      <td>terimakasih pak de saya seorang tukang ojek ka...</td>\n",
       "      <td>terimakasih pak de saya seorang tukang ojek ka...</td>\n",
       "      <td>[terimakasih, pak, de, saya, seorang, tukang, ...</td>\n",
       "      <td>terimakasih pak de saya seorang tukang ojek ka...</td>\n",
       "      <td>[terimakasih, bapak, de, saya, seorang, tukang...</td>\n",
       "      <td>[terimakasih, bapak, de, saya, orang, tukang, ...</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Saya sebagai rakyat kecil mendengar bbm naik s...</td>\n",
       "      <td>Davin Davin</td>\n",
       "      <td>Saya sebagai rakyat kecil mendengar bbm naik s...</td>\n",
       "      <td>saya sebagai rakyat kecil mendengar bbm naik s...</td>\n",
       "      <td>saya sebagai rakyat kecil mendengar bbm naik s...</td>\n",
       "      <td>[saya, sebagai, rakyat, kecil, mendengar, bbm,...</td>\n",
       "      <td>saya sebagai rakyat kecil mendengar bbm naik s...</td>\n",
       "      <td>[saya, sebagai, rakyat, kecil, mendengar, bbm,...</td>\n",
       "      <td>[saya, bagai, rakyat, kecil, dengar, bbm, naik...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Terima kasih banyak Pak Jokowi. Kebijakan Bapa...</td>\n",
       "      <td>Zul Haqqi</td>\n",
       "      <td>Terima kasih banyak Pak Jokowi. Kebijakan Bapa...</td>\n",
       "      <td>terima kasih banyak pak jokowi kebijakan bapak...</td>\n",
       "      <td>terima kasih banyak pak jokowi kebijakan bapak...</td>\n",
       "      <td>[terima, kasih, banyak, pak, jokowi, kebijakan...</td>\n",
       "      <td>terima kasih banyak pak jokowi kebijakan bapak...</td>\n",
       "      <td>[terima, kasih, banyak, bapak, jokowi, kebijak...</td>\n",
       "      <td>[terima, kasih, banyak, bapak, jokowi, bijak, ...</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Semoga Allah SWT memudahkan semua urusan rakya...</td>\n",
       "      <td>R.E. Handhita</td>\n",
       "      <td>Semoga Allah SWT memudahkan semua urusan rakya...</td>\n",
       "      <td>semoga allah swt memudahkan semua urusan rakya...</td>\n",
       "      <td>semoga allah swt memudahkan semua urusan rakya...</td>\n",
       "      <td>[semoga, allah, swt, memudahkan, semua, urusan...</td>\n",
       "      <td>semoga allah swt memudahkan semua urusan rakya...</td>\n",
       "      <td>[semoga, allah, swt, memudahkan, semua, urusan...</td>\n",
       "      <td>[moga, allah, swt, mudah, semua, urus, rakyat,...</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text             author  \\\n",
       "0  Turunkan tunjangan untuk DPR, alihkan untuk su...  abu studio chanel   \n",
       "1  Terimakasih pak de Saya seorang tukang ojek ka...           al rozaq   \n",
       "2  Saya sebagai rakyat kecil mendengar bbm naik s...        Davin Davin   \n",
       "3  Terima kasih banyak Pak Jokowi. Kebijakan Bapa...          Zul Haqqi   \n",
       "4  Semoga Allah SWT memudahkan semua urusan rakya...      R.E. Handhita   \n",
       "\n",
       "                                               emoji  \\\n",
       "0  Turunkan tunjangan untuk DPR, alihkan untuk su...   \n",
       "1  Terimakasih pak de Saya seorang tukang ojek ka...   \n",
       "2  Saya sebagai rakyat kecil mendengar bbm naik s...   \n",
       "3  Terima kasih banyak Pak Jokowi. Kebijakan Bapa...   \n",
       "4  Semoga Allah SWT memudahkan semua urusan rakya...   \n",
       "\n",
       "                                           cleantext  \\\n",
       "0  turunkan tunjangan untuk dpr alihkan untuk sub...   \n",
       "1  terimakasih pak de saya seorang tukang ojek ka...   \n",
       "2  saya sebagai rakyat kecil mendengar bbm naik s...   \n",
       "3  terima kasih banyak pak jokowi kebijakan bapak...   \n",
       "4  semoga allah swt memudahkan semua urusan rakya...   \n",
       "\n",
       "                                           terbilang  \\\n",
       "0  turunkan tunjangan untuk dpr alihkan untuk sub...   \n",
       "1  terimakasih pak de saya seorang tukang ojek ka...   \n",
       "2  saya sebagai rakyat kecil mendengar bbm naik s...   \n",
       "3  terima kasih banyak pak jokowi kebijakan bapak...   \n",
       "4  semoga allah swt memudahkan semua urusan rakya...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [turunkan, tunjangan, untuk, dpr, alihkan, unt...   \n",
       "1  [terimakasih, pak, de, saya, seorang, tukang, ...   \n",
       "2  [saya, sebagai, rakyat, kecil, mendengar, bbm,...   \n",
       "3  [terima, kasih, banyak, pak, jokowi, kebijakan...   \n",
       "4  [semoga, allah, swt, memudahkan, semua, urusan...   \n",
       "\n",
       "                                            delangka  \\\n",
       "0  turunkan tunjangan untuk dpr alihkan untuk sub...   \n",
       "1  terimakasih pak de saya seorang tukang ojek ka...   \n",
       "2  saya sebagai rakyat kecil mendengar bbm naik s...   \n",
       "3  terima kasih banyak pak jokowi kebijakan bapak...   \n",
       "4  semoga allah swt memudahkan semua urusan rakya...   \n",
       "\n",
       "                                         normalisasi  \\\n",
       "0  [turunkan, tunjangan, untuk, dpr, alihkan, unt...   \n",
       "1  [terimakasih, bapak, de, saya, seorang, tukang...   \n",
       "2  [saya, sebagai, rakyat, kecil, mendengar, bbm,...   \n",
       "3  [terima, kasih, banyak, bapak, jokowi, kebijak...   \n",
       "4  [semoga, allah, swt, memudahkan, semua, urusan...   \n",
       "\n",
       "                                             stemmed  polarity    label  \n",
       "0  [turun, tunjang, untuk, dpr, alih, untuk, subs...   -0.0024  negatif  \n",
       "1  [terimakasih, bapak, de, saya, orang, tukang, ...   -0.0011  negatif  \n",
       "2  [saya, bagai, rakyat, kecil, dengar, bbm, naik...    0.0000  positif  \n",
       "3  [terima, kasih, banyak, bapak, jokowi, bijak, ...    0.0090  positif  \n",
       "4  [moga, allah, swt, mudah, semua, urus, rakyat,...    0.0282  positif  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('sentimen_analisis.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def translate_emoticon(text):\n",
    "        load_emoji = None\n",
    "        with open('emoji/emoticon.json') as f:\n",
    "            load_emoji = json.load(f)\n",
    "        for index, keys in enumerate(load_emoji.keys()):\n",
    "            text = text.replace(keys, load_emoji[keys])\n",
    "        return text\n",
    "\n",
    "def convert_emoji(text):\n",
    "        text = re.sub('@[^\\s]+','', text)\n",
    "        text = re.sub('#[^\\s]+','', text)\n",
    "        text = emoji.demojize(text)\n",
    "        text = text.replace(':', ' ')\n",
    "        text = ' '.join(text.split())\n",
    "        return text\n",
    "\n",
    "def translate_emoji(text):\n",
    "        df_emoji = pd.read_csv('emoji/emoji.csv')\n",
    "        for index, row in df_emoji.iterrows():\n",
    "            text = text.replace(row[1].replace(' ', '_'), row[5])\n",
    "        return text\n",
    "\n",
    "def clean(text):\n",
    "        text = text.lower().strip() #Ubah Ke Lowercase\n",
    "        text = re.sub('@[^\\s]+','',text) #Menghapus Username\n",
    "        text = ' '.join(re.sub(\"(rt )\",\" \", text).split()) #Menghapus kata 'rt'\n",
    "        text = re.sub('((www\\S+)|(http\\S+))', ' ', text) #Menghapus URL\n",
    "        text = text.encode('ascii', 'replace').decode('ascii') #remove non ASCII (emoticon, chinese word, .etc)\n",
    "        text = text.replace('\\\\t',\" \").replace('\\\\n',\" \").replace('\\\\u',\" \").replace('\\\\',\"\") #remove tab, new line, ans back slice\n",
    "        text = text.translate(str.maketrans('','',string.punctuation)) #Menghapus Punctuation\n",
    "        return text\n",
    "\n",
    "def terbilang(text):\n",
    "        kata = text.split()\n",
    "        hasil =[]\n",
    "        k = 0\n",
    "        for i in kata:\n",
    "                k = k + 1\n",
    "                if i.isdigit():\n",
    "                        h = num2words(int(i), lang='id').split()\n",
    "                        hasil.extend(h)\n",
    "                        continue\n",
    "                hasil.extend([i])\n",
    "        return ' '.join(hasil)\n",
    "\n",
    "def delangka(text):\n",
    "      text = re.sub(r'\\d+', ' ', text)\n",
    "      return text\n",
    "\n",
    "def tokenize(column):\n",
    "    \"\"\"Tokenizes a Pandas dataframe column and returns a list of tokens.\n",
    "\n",
    "    Args:\n",
    "        column: Pandas dataframe column (i.e. df['text']).\n",
    "\n",
    "    Returns:\n",
    "        tokens (list): Tokenized list, i.e. [Donald, Trump, tweets]\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = nltk.word_tokenize(column)\n",
    "    return [w for w in tokens if w.isalpha()]  \n",
    "\n",
    "def load_dataset_normalization():\n",
    "        load_word = pd.read_csv('normalisasi/normalisasi2.csv')\n",
    "        normal_word_dict = {}\n",
    "        for index, row in load_word.iterrows():\n",
    "            if row[0] not in normal_word_dict:\n",
    "                normal_word_dict[row[0]] = row[1]\n",
    "        return normal_word_dict\n",
    "\n",
    "def normalisasi(data):\n",
    "        word_dict = load_dataset_normalization()\n",
    "        return [word_dict[term] if term in word_dict else term for term in data]\n",
    "\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "def stemming(data):\n",
    "        lengthData = len(data)\n",
    "        base = []\n",
    "        count = 0\n",
    "        for list_text in data:\n",
    "            for text in list_text:\n",
    "                base.append(stemmer.stem(text))\n",
    "            count = count + 1\n",
    "        return base\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'translate_emoticon' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dedys\\Documents\\Analisis Sentimen\\Scripsi\\a_sudahjadi\\analisis1.ipynb Cell 5\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dedys/Documents/Analisis%20Sentimen/Scripsi/a_sudahjadi/analisis1.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39memoji\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(translate_emoticon)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dedys/Documents/Analisis%20Sentimen/Scripsi/a_sudahjadi/analisis1.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39memoji\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39memoji\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(convert_emoji)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dedys/Documents/Analisis%20Sentimen/Scripsi/a_sudahjadi/analisis1.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39memoji\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39memoji\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(translate_emoji)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'translate_emoticon' is not defined"
     ]
    }
   ],
   "source": [
    "df[\"emoji\"] = df[\"text\"].apply(translate_emoticon)\n",
    "df[\"emoji\"] = df[\"emoji\"].apply(convert_emoji)\n",
    "df[\"emoji\"] = df[\"emoji\"].apply(translate_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cleantext\"] = df[\"emoji\"].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"terbilang\"] = df[\"cleantext\"].apply(terbilang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"delangka\"] = df['terbilang'].apply(delangka)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized'] = df.apply(lambda x: tokenize(x['delangka']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"normalisasi\"] = df[\"tokenized\"].apply(normalisasi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitung=0\n",
    "listku = [[] for i in range(0, len(df[\"normalisasi\"]))]\n",
    "for list_text in df['normalisasi']:\n",
    "    for text in list_text:\n",
    "        listku[hitung].append(stemmer.stem(text))\n",
    "    hitung = hitung + 1\n",
    "\n",
    "\n",
    "df[\"stemmed\"] = listku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import json\n",
    "import reprlib\n",
    "\n",
    "# Memanfaatkan nltk VADER untuk menggunakan leksikon kustom\n",
    "sia1A, sia1B, sia2 = SentimentIntensityAnalyzer(), SentimentIntensityAnalyzer(), SentimentIntensityAnalyzer()\n",
    "# membersihkan leksikon VADER default\n",
    "sia1A.lexicon.clear()\n",
    "sia1B.lexicon.clear()\n",
    "sia2.lexicon.clear()\n",
    "\n",
    "# Membaca leksikon InSet\n",
    "# Leksikon InSet lexicon dibagi menjadi dua, yakni polaritas negatif dan polaritas positif;\n",
    "# kita akan menggunakan nilai compound saja untuk memberi label pada suatu kalimat\n",
    "with open('leksikon/inset/_json_inset-neg.txt') as f:\n",
    "    data1A = f.read()\n",
    "with open('leksikon/inset/_json_inset-pos.txt') as f:\n",
    "    data1B = f.read()\n",
    "# Membaca leksikon sentiwords_id\n",
    "with open('leksikon/sentistrength_id/_json_sentiwords_id.txt') as f:\n",
    "    data2 = f.read()\n",
    "\n",
    "\n",
    "# Mengubah leksikon sebagai dictionary\n",
    "insetNeg = json.loads(data1A)\n",
    "insetPos = json.loads(data1B)\n",
    "senti = json.loads(data2)\n",
    "\n",
    "# Update leksikon VADER yang sudah 'dimodifikasi'\n",
    "sia1A.lexicon.update(insetNeg)\n",
    "sia1B.lexicon.update(insetPos)\n",
    "sia2.lexicon.update(senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_positive_inset(tweet: str):\n",
    "    \"\"\"True if tweet has positive compound sentiment, False otherwise.\"\"\"\n",
    "    return sia1A.polarity_scores(tweet)[\"compound\"] + sia1B.polarity_scores(tweet)[\"compound\"]\n",
    "\n",
    "def is_positive_senti(tweet: str):\n",
    "    \"\"\"True if tweet has positive compound sentiment, False otherwise.\"\"\"\n",
    "    return sia2.polarity_scores(tweet)[\"compound\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity = []\n",
    "dataku = df['stemmed']\n",
    "for komen in dataku:\n",
    "        polarity.append(is_positive_inset(' '.join(komen)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in polarity:\n",
    "    if i >= 0:\n",
    "        labels.append('positif')\n",
    "    else:\n",
    "        labels.append('negatif')\n",
    "\n",
    "\n",
    "df[\"polarity\"] = polarity\n",
    "df[\"label\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"sentimen_analisis.json\", orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>emoji</th>\n",
       "      <th>cleantext</th>\n",
       "      <th>terbilang</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>delangka</th>\n",
       "      <th>normalisasi</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negatif</th>\n",
       "      <td>2041</td>\n",
       "      <td>2041</td>\n",
       "      <td>2041</td>\n",
       "      <td>2041</td>\n",
       "      <td>2041</td>\n",
       "      <td>2041</td>\n",
       "      <td>2041</td>\n",
       "      <td>2041</td>\n",
       "      <td>2041</td>\n",
       "      <td>2041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positif</th>\n",
       "      <td>959</td>\n",
       "      <td>959</td>\n",
       "      <td>959</td>\n",
       "      <td>959</td>\n",
       "      <td>959</td>\n",
       "      <td>959</td>\n",
       "      <td>959</td>\n",
       "      <td>959</td>\n",
       "      <td>959</td>\n",
       "      <td>959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text  author  emoji  cleantext  terbilang  tokenized  delangka  \\\n",
       "label                                                                     \n",
       "negatif  2041    2041   2041       2041       2041       2041      2041   \n",
       "positif   959     959    959        959        959        959       959   \n",
       "\n",
       "         normalisasi  stemmed  polarity  \n",
       "label                                    \n",
       "negatif         2041     2041      2041  \n",
       "positif          959      959       959  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"label\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delangka'].to_csv('data_train_fasttext.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df15aba01cad53e519ddd0ed5c2ff79632f75579aad31d70b3fb2ecc510f83fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
