{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.load_model('cc.id.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>cleantext</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>stemming</th>\n",
       "      <th>polarity</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turunkan tunjangan untuk DPR, alihkan untuk su...</td>\n",
       "      <td>abu studio chanel</td>\n",
       "      <td>turunkan tunjangan untuk dpr alihkan untuk sub...</td>\n",
       "      <td>[turunkan, tunjangan, untuk, dpr, alihkan, unt...</td>\n",
       "      <td>[turun, tunjang, untuk, dpr, alih, untuk, subs...</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Terimakasih pak de Saya seorang tukang ojek ka...</td>\n",
       "      <td>al rozaq</td>\n",
       "      <td>terimakasih pak de saya seorang tukang ojek ka...</td>\n",
       "      <td>[terimakasih, pak, de, saya, seorang, tukang, ...</td>\n",
       "      <td>[terimakasih, pak, de, saya, orang, tukang, oj...</td>\n",
       "      <td>-0.0013</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Saya sebagai rakyat kecil mendengar bbm naik s...</td>\n",
       "      <td>Davin Davin</td>\n",
       "      <td>saya sebagai rakyat kecil mendengar bbm naik s...</td>\n",
       "      <td>[saya, sebagai, rakyat, kecil, mendengar, bbm,...</td>\n",
       "      <td>[saya, bagai, rakyat, kecil, dengar, bbm, naik...</td>\n",
       "      <td>-0.0067</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Terima kasih banyak Pak Jokowi. Kebijakan Bapa...</td>\n",
       "      <td>Zul Haqqi</td>\n",
       "      <td>terima kasih banyak pak jokowi kebijakan bapak...</td>\n",
       "      <td>[terima, kasih, banyak, pak, jokowi, kebijakan...</td>\n",
       "      <td>[terima, kasih, banyak, pak, jokowi, bijak, ba...</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Semoga Allah SWT memudahkan semua urusan rakya...</td>\n",
       "      <td>R.E. Handhita</td>\n",
       "      <td>semoga allah swt memudahkan semua urusan rakya...</td>\n",
       "      <td>[semoga, allah, swt, memudahkan, semua, urusan...</td>\n",
       "      <td>[moga, allah, swt, mudah, semua, urus, rakyat,...</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>Pupuk subsidi langka,,, \\nBBM naik,,, \\nHarga ...</td>\n",
       "      <td>Heru Purnomo</td>\n",
       "      <td>pupuk subsidi langka bbm naik harga gabah dan ...</td>\n",
       "      <td>[pupuk, subsidi, langka, bbm, naik, harga, gab...</td>\n",
       "      <td>[pupuk, subsidi, langka, bbm, naik, harga, gab...</td>\n",
       "      <td>-0.2002</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>Saya berharap bbm turun. Kasihan anak kost di ...</td>\n",
       "      <td>Nerry_shop</td>\n",
       "      <td>saya berharap bbm turun kasihan anak kost di p...</td>\n",
       "      <td>[saya, berharap, bbm, turun, kasihan, anak, ko...</td>\n",
       "      <td>[saya, harap, bbm, turun, kasihan, anak, kost,...</td>\n",
       "      <td>-0.0557</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>saran saya daripada ngasih BLT yg tidak merata...</td>\n",
       "      <td>jubez gaming</td>\n",
       "      <td>saran saya daripada ngasih blt yg tidak merata...</td>\n",
       "      <td>[saran, saya, daripada, ngasih, blt, yg, tidak...</td>\n",
       "      <td>[saran, saya, daripada, ngasih, blt, yg, tidak...</td>\n",
       "      <td>-0.0042</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>Presiden blusukan mantapp ðŸ˜‚</td>\n",
       "      <td>dea bagas</td>\n",
       "      <td>presiden blusukan mantapp</td>\n",
       "      <td>[presiden, blusukan, mantapp]</td>\n",
       "      <td>[presiden, blusukan, mantapp]</td>\n",
       "      <td>0.6124</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>Dari dulu hingga skarang sama harga bukn turun...</td>\n",
       "      <td>Jono no</td>\n",
       "      <td>dari dulu hingga skarang sama harga bukn turun...</td>\n",
       "      <td>[dari, dulu, hingga, skarang, sama, harga, buk...</td>\n",
       "      <td>[dari, dulu, hingga, skarang, sama, harga, buk...</td>\n",
       "      <td>0.0233</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text             author  \\\n",
       "0     Turunkan tunjangan untuk DPR, alihkan untuk su...  abu studio chanel   \n",
       "1     Terimakasih pak de Saya seorang tukang ojek ka...           al rozaq   \n",
       "2     Saya sebagai rakyat kecil mendengar bbm naik s...        Davin Davin   \n",
       "3     Terima kasih banyak Pak Jokowi. Kebijakan Bapa...          Zul Haqqi   \n",
       "4     Semoga Allah SWT memudahkan semua urusan rakya...      R.E. Handhita   \n",
       "...                                                 ...                ...   \n",
       "2995  Pupuk subsidi langka,,, \\nBBM naik,,, \\nHarga ...       Heru Purnomo   \n",
       "2996  Saya berharap bbm turun. Kasihan anak kost di ...         Nerry_shop   \n",
       "2997  saran saya daripada ngasih BLT yg tidak merata...       jubez gaming   \n",
       "2998                        Presiden blusukan mantapp ðŸ˜‚          dea bagas   \n",
       "2999  Dari dulu hingga skarang sama harga bukn turun...            Jono no   \n",
       "\n",
       "                                              cleantext  \\\n",
       "0     turunkan tunjangan untuk dpr alihkan untuk sub...   \n",
       "1     terimakasih pak de saya seorang tukang ojek ka...   \n",
       "2     saya sebagai rakyat kecil mendengar bbm naik s...   \n",
       "3     terima kasih banyak pak jokowi kebijakan bapak...   \n",
       "4     semoga allah swt memudahkan semua urusan rakya...   \n",
       "...                                                 ...   \n",
       "2995  pupuk subsidi langka bbm naik harga gabah dan ...   \n",
       "2996  saya berharap bbm turun kasihan anak kost di p...   \n",
       "2997  saran saya daripada ngasih blt yg tidak merata...   \n",
       "2998                          presiden blusukan mantapp   \n",
       "2999  dari dulu hingga skarang sama harga bukn turun...   \n",
       "\n",
       "                                              tokenized  \\\n",
       "0     [turunkan, tunjangan, untuk, dpr, alihkan, unt...   \n",
       "1     [terimakasih, pak, de, saya, seorang, tukang, ...   \n",
       "2     [saya, sebagai, rakyat, kecil, mendengar, bbm,...   \n",
       "3     [terima, kasih, banyak, pak, jokowi, kebijakan...   \n",
       "4     [semoga, allah, swt, memudahkan, semua, urusan...   \n",
       "...                                                 ...   \n",
       "2995  [pupuk, subsidi, langka, bbm, naik, harga, gab...   \n",
       "2996  [saya, berharap, bbm, turun, kasihan, anak, ko...   \n",
       "2997  [saran, saya, daripada, ngasih, blt, yg, tidak...   \n",
       "2998                      [presiden, blusukan, mantapp]   \n",
       "2999  [dari, dulu, hingga, skarang, sama, harga, buk...   \n",
       "\n",
       "                                               stemming  polarity   labels  \n",
       "0     [turun, tunjang, untuk, dpr, alih, untuk, subs...   -0.0024  negatif  \n",
       "1     [terimakasih, pak, de, saya, orang, tukang, oj...   -0.0013  negatif  \n",
       "2     [saya, bagai, rakyat, kecil, dengar, bbm, naik...   -0.0067  negatif  \n",
       "3     [terima, kasih, banyak, pak, jokowi, bijak, ba...    0.0090  positif  \n",
       "4     [moga, allah, swt, mudah, semua, urus, rakyat,...    0.1049  positif  \n",
       "...                                                 ...       ...      ...  \n",
       "2995  [pupuk, subsidi, langka, bbm, naik, harga, gab...   -0.2002  negatif  \n",
       "2996  [saya, harap, bbm, turun, kasihan, anak, kost,...   -0.0557  negatif  \n",
       "2997  [saran, saya, daripada, ngasih, blt, yg, tidak...   -0.0042  negatif  \n",
       "2998                      [presiden, blusukan, mantapp]    0.6124  positif  \n",
       "2999  [dari, dulu, hingga, skarang, sama, harga, buk...    0.0233  positif  \n",
       "\n",
       "[3000 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('datalabels_inset_3.json')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text          object\n",
       "author        object\n",
       "cleantext     object\n",
       "tokenized     object\n",
       "stemming      object\n",
       "polarity     float64\n",
       "labels        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleantext'].to_csv('cleantext.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_unsupervised('cleantext.txt', minn=2, maxn=6, dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "coba = model.get_sentence_vector('saya sayang kamu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "for i in df['stemming']:\n",
    "    arr.append(model.get_sentence_vector(' '.join(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labenc = LabelEncoder()\n",
    "label = df['labels'].values\n",
    "y = labenc.fit_transform(label)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(arr,y,test_size = 0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=clf.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nilai Akurasi :  0.5573333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.95      0.71       419\n",
      "           1       0.49      0.06      0.11       331\n",
      "\n",
      "    accuracy                           0.56       750\n",
      "   macro avg       0.52      0.51      0.41       750\n",
      "weighted avg       0.53      0.56      0.44       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"Nilai Akurasi : \",accuracy_score(ytest,ypred))\n",
    "print(classification_report(ytest,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0,\n",
       "       2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2,\n",
       "       0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasil = [coba]\n",
    "clf.predict(hasil)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df15aba01cad53e519ddd0ed5c2ff79632f75579aad31d70b3fb2ecc510f83fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
